{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSsGab9RyR9R"
      },
      "outputs": [],
      "source": [
        "# --- Imports and API Key Setup ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "client = OpenAI (\n",
        "    api_key = \"YOUR_API_KEY_HERE\"\n",
        "    )\n",
        "\n",
        "print(\"Libraries imported and OpenAI key set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsT3RcsJyYiI"
      },
      "outputs": [],
      "source": [
        "# --- Load Data ---\n",
        "\n",
        "file_path = \"CSV_FILE_PATH_HERE\" # We used a CSV file with two columns: 'gesture_name' and 'gesture_definition'\n",
        "try:\n",
        "    df = pd.read_csv(file_path, sep=\";\", quotechar='\"', encoding=\"utf-8-sig\")\n",
        "    df = df[['gesture_name', 'gesture_definition']]\n",
        "    df = df.dropna(subset=['gesture_name', 'gesture_definition'])\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"Successfully loaded {len(df)} gestures from '{file_path}'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    df = None\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT0HEvoMyaXC"
      },
      "outputs": [],
      "source": [
        "# --- Generate Sentence Embeddings ---\n",
        "\n",
        "if df is not None:\n",
        "    print(\"Initializing sentence transformer model ('all-mpnet-base-v2')...\")\n",
        "    model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "    print(\"Generating embeddings for all definitions. This may take a moment...\")\n",
        "    try:\n",
        "        # Store definitions in a list\n",
        "        definitions = df['gesture_definition'].tolist()\n",
        "\n",
        "        # Generate embeddings\n",
        "        X = model.encode(definitions, show_progress_bar=True)\n",
        "\n",
        "        print(f\"Embeddings generated successfully. Shape: {X.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embeddings: {e}\")\n",
        "        X = None\n",
        "else:\n",
        "    print(\"Skipping embedding generation as data was not loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jedzDn4bycfi"
      },
      "outputs": [],
      "source": [
        "# --- Deduplication ---\n",
        "\n",
        "if X is not None:\n",
        "    print(\"Performing deduplication...\")\n",
        "\n",
        "    # Calculate cosine similarity matrix\n",
        "    similarity_matrix = cosine_similarity(X)\n",
        "\n",
        "    # Set a high threshold for synonyms\n",
        "    SIMILARITY_THRESHOLD = 0.90\n",
        "\n",
        "    merged_indices = set()\n",
        "    representatives = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if i in merged_indices:\n",
        "            continue\n",
        "\n",
        "        # Find all gestures highly similar to gesture 'i'\n",
        "        similar_indices = np.where(similarity_matrix[i] >= SIMILARITY_THRESHOLD)[0]\n",
        "\n",
        "        # The representative is the first one in the group\n",
        "        rep_index = similar_indices[0]\n",
        "        rep_name = df.iloc[rep_index]['gesture_name']\n",
        "        rep_def = df.iloc[rep_index]['gesture_definition']\n",
        "\n",
        "        # Get names of all gestures being merged into this one\n",
        "        synonym_names = [df.iloc[j]['gesture_name'] for j in similar_indices if j != rep_index]\n",
        "\n",
        "        representatives.append({\n",
        "            'representative_name': rep_name,\n",
        "            'representative_definition': rep_def,\n",
        "            'synonyms': synonym_names,\n",
        "            'original_index': rep_index # Store original index to retrieve embedding\n",
        "        })\n",
        "\n",
        "        # Add all merged gestures to a set to skip them\n",
        "        merged_indices.update(similar_indices)\n",
        "\n",
        "    # Create the new deduplicated dataframe\n",
        "    dedup_df = pd.DataFrame(representatives)\n",
        "\n",
        "    # Create the new embedding matrix 'X_dedup' by selecting only the embeddings of the representative gestures\n",
        "    representative_indices = dedup_df['original_index'].tolist()\n",
        "    X_dedup = X[representative_indices, :]\n",
        "\n",
        "    print(f\"Deduplication complete.\")\n",
        "    print(f\"Original gesture count: {len(df)}\")\n",
        "    print(f\"Deduplicated gesture count: {len(dedup_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping deduplication as embeddings were not generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNq7Fum1yeRn"
      },
      "outputs": [],
      "source": [
        "# --- Real LLM Helper Functions ---\n",
        "\n",
        "# --- Function 1: Get Cluster Labels ---\n",
        "def get_cluster_labels(cluster_gestures: list) -> dict:\n",
        "    \"\"\"\n",
        "    Calls the OpenAI API (v1.0.0) to generate a label and definition.\n",
        "    \"\"\"\n",
        "    gesture_list_str = \"\\n- \".join(cluster_gestures)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following is a cluster of surgical gestures:\n",
        "    - {gesture_list_str}\n",
        "\n",
        "    Your task is to act as an expert in robotic/minimally-invasive surgery. Analyze this list and\n",
        "    propose a concise taxonomic label and a short, clear definition\n",
        "    for this group of actions. Assume a hirarchical taxonomy in which some labels contain sub-gestures.\n",
        "\n",
        "    Return your answer in a strict JSON format.\n",
        "    Example:\n",
        "    {{\n",
        "      \"label\": \"Stapling\",\n",
        "      \"definition\": \"Using a mechanical device to join or separate tissues.\"\n",
        "      \"label\": \"Clip\",\n",
        "      \"definition\": \"A clip applier is activated to deploy one or more clips across a vessel or structure to occlude it.\"\n",
        "    }}\n",
        "\n",
        "    JSON response:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            response_format={ \"type\": \"json_object\" }, # Use new JSON mode\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns JSON.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "        )\n",
        "\n",
        "        # --- RESPONSE PARSING ---\n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_cluster_labels: {e}\")\n",
        "        return {\"label\": \"Error - API Call Failed\", \"definition\": str(e)}\n",
        "\n",
        "# --- Function 2: Check Cluster Homogeneity (with Scoring) ---\n",
        "def check_cluster_homogeneity(cluster_gestures: list) -> dict:\n",
        "    \"\"\"\n",
        "    Calls the OpenAI API (v1.0.0) to rate the semantic consistency.\n",
        "    \"\"\"\n",
        "    gesture_list_str = \"\\n- \".join(cluster_gestures)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are expert in robotic/minimally-invasive surgery, and is creating the\n",
        "    taxonomy for robotic surgical gestures. On a scale of 1 to 10,\n",
        "    where 1 is a completely mixed bag of random concepts and 10 is a\n",
        "    perfectly consistent set of similar/hirarchical terms, please rate the semantic\n",
        "    consistency of this gesture cluster:\n",
        "\n",
        "    - {gesture_list_str}\n",
        "\n",
        "    A \"heterogeneous\" cluster (score < 5) might mix actions like\n",
        "    \"Clip\" with \"Camera Move\". A \"homogeneous\" cluster (score >= 5)\n",
        "    would contain only variations of a single concept, like\n",
        "    \"Dissection\", \"Dissection - Sharp\", \"Dissection - Electrosurgery\".\n",
        "\n",
        "    Return a strict JSON object with your score and a brief reason.\n",
        "    Example:\n",
        "    {{\n",
        "      \"consistency_score\": 8,\n",
        "      \"reason\": \"All gestures relate to cutting tissue.\"\n",
        "    }}\n",
        "\n",
        "    JSON response:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            response_format={ \"type\": \"json_object\" },\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns JSON.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "        )\n",
        "\n",
        "        # --- RESPONSE PARSING ---\n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in check_cluster_homogeneity: {e}\")\n",
        "        return {\"consistency_score\": 1, \"reason\": f\"API Call Failed: {e}\"}\n",
        "\n",
        "print(\"Real LLM helper functions (v1.0.0 syntax) defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnqc4iqCyfvx"
      },
      "outputs": [],
      "source": [
        "# --- Agglomerative Clustering Strategy ---\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import time\n",
        "\n",
        "if 'X_dedup' in locals() and 'dedup_df' in locals():\n",
        "    print(\"--- Starting Agglomerative Clustering Strategy ---\")\n",
        "\n",
        "    final_taxonomy = []\n",
        "\n",
        "    # --- TUNING PARAMETERS ---\n",
        "    # The maximum cosine *distance* allowed in a cluster.\n",
        "    # 0.5 = ~50% similarity\n",
        "    # 0.4 = ~60% similarity\n",
        "    # 0.3 = ~70% similarity (Where we started)\n",
        "    DISTANCE_THRESHOLD = 0.4\n",
        "    # --- --- --- --- --- --- --- --- ---\n",
        "\n",
        "    df_to_cluster = dedup_df.copy()\n",
        "    X_to_cluster = X_dedup\n",
        "\n",
        "    # 1. Initialize and run Agglomerative Clustering\n",
        "    # We use metric='cosine'\n",
        "    # and linkage='average'\n",
        "    print(f\"Running Agglomerative Clustering with distance_threshold={DISTANCE_THRESHOLD}...\")\n",
        "\n",
        "    agg_cluster = AgglomerativeClustering(\n",
        "        n_clusters=None,\n",
        "        metric='cosine', \n",
        "        linkage='average',\n",
        "        distance_threshold=DISTANCE_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # Fit and get the cluster labels\n",
        "    df_to_cluster['cluster'] = agg_cluster.fit_predict(X_to_cluster)\n",
        "\n",
        "    num_clusters_found = df_to_cluster['cluster'].nunique()\n",
        "    print(f\"Clustering complete. Found {num_clusters_found} clusters.\")\n",
        "\n",
        "    # 2. Loop through the found clusters and get LLM labels\n",
        "\n",
        "    print(\"\\nProceeding to final labeling...\")\n",
        "\n",
        "    for i in range(num_clusters_found):\n",
        "        gestures_in_cluster_df = df_to_cluster[df_to_cluster['cluster'] == i]\n",
        "        gestures_list = gestures_in_cluster_df['representative_name'].tolist()\n",
        "\n",
        "        if not gestures_list:\n",
        "            continue\n",
        "\n",
        "        # 3. Get final label and definition from LLM\n",
        "        print(f\"  Labeling final cluster {i} (size={len(gestures_list)})...\")\n",
        "        time.sleep(1)  # Sleep to avoid hitting rate limits\n",
        "\n",
        "        labels = get_cluster_labels(gestures_list)\n",
        "\n",
        "        final_taxonomy.append({\n",
        "            'cluster_id': i,\n",
        "            'llm_label': labels.get('label', 'Error'),\n",
        "            'llm_definition': labels.get('definition', 'Error'),\n",
        "            'gestures': gestures_list,\n",
        "            'synonyms_included': [s for syn_list in gestures_in_cluster_df['synonyms'] for s in syn_list]\n",
        "        })\n",
        "\n",
        "    print(\"All clusters labeled.\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping main loop because data or embeddings are missing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gALBY6dLyhGG"
      },
      "outputs": [],
      "source": [
        "# --- Display Final Taxonomy ---\n",
        "\n",
        "if final_taxonomy:\n",
        "    print(f\"\\n--- Process Complete ---\")\n",
        "    print(f\"Generated {len(final_taxonomy)} final clusters (K={num_clusters_found}).\\n\")\n",
        "\n",
        "    # Print the final taxonomy\n",
        "    for cluster in final_taxonomy:\n",
        "        print(f\"==================================================\")\n",
        "        print(f\"Cluster ID: {cluster['cluster_id']}\")\n",
        "        print(f\"LLM Label: {cluster['llm_label']}\")\n",
        "        print(f\"LLM Definition: {cluster['llm_definition']}\")\n",
        "        print(f\"Representative Gestures ({len(cluster['gestures'])}):\")\n",
        "        # Print only first 5 gestures\n",
        "        for gesture in cluster['gestures'][:5]:\n",
        "            print(f\"  - {gesture}\")\n",
        "        if len(cluster['gestures']) > 5:\n",
        "            print(f\"  ... and {len(cluster['gestures']) - 5} more.\")\n",
        "\n",
        "        if cluster['synonyms_included']:\n",
        "            print(f\"Synonyms Included ({len(cluster['synonyms_included'])}):\")\n",
        "            print(f\"  {', '.join(cluster['synonyms_included'][:5])}...\")\n",
        "        print(f\"==================================================\")\n",
        "\n",
        "    # Save to a JSON file\n",
        "    try:\n",
        "        with open(\"final_taxonomy.json\", \"w\") as f:\n",
        "            json.dump(final_taxonomy, f, indent=2)\n",
        "        print(\"\\nSuccessfully saved final taxonomy to 'final_taxonomy.json'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCould not save taxonomy to file: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo final taxonomy was generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4iJdpnDyibB"
      },
      "outputs": [],
      "source": [
        "# --- Load and Inspect the Final Taxonomy ---\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    with open(\"final_taxonomy.json\", \"r\") as f:\n",
        "        final_taxonomy_data = json.load(f)\n",
        "\n",
        "    # Convert to a dataframe for easy viewing\n",
        "    taxonomy_df = pd.DataFrame(final_taxonomy_data)\n",
        "\n",
        "    # Display key columns\n",
        "    print(f\"Taxonomy loaded. Found {len(taxonomy_df)} clusters.\")\n",
        "    print(\"\\nOverview of Clusters:\")\n",
        "    print(taxonomy_df[['cluster_id', 'llm_label', 'llm_definition', 'gestures']].head(10))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'final_taxonomy.json' not found. Ensure Cell 6 ran successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq3wtGFHyje-"
      },
      "outputs": [],
      "source": [
        "# --- Generate Clustermap for Visual Validation ---\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "# Use the deduplicated data and embeddings\n",
        "labels = dedup_df['representative_name']\n",
        "X_embeddings = X_dedup\n",
        "\n",
        "# 1. Compute cosine distance matrix (necessary for the plot)\n",
        "# dist_matrix = cosine_distances(X_embeddings)\n",
        "# NOTE: To use Ward linkage (default for clustermap), must use Euclidean distance on normalized vectors, which is proportional to squared cosine distance.\n",
        "# We used the standard Euclidean distance for simplicity and compatibility.\n",
        "dist_matrix = cosine_distances(X_embeddings)\n",
        "\n",
        "# 2. Create a DataFrame for seaborn with gesture labels\n",
        "df_dist = pd.DataFrame(dist_matrix, index=labels, columns=labels)\n",
        "\n",
        "# 3. Plot clustermap\n",
        "sns.set(font_scale=0.4)\n",
        "\n",
        "g = sns.clustermap(\n",
        "    df_dist,\n",
        "    metric='cosine',\n",
        "    method='average',\n",
        "    cmap='viridis',\n",
        "    figsize=(20, 20),\n",
        "    row_cluster=True,\n",
        "    col_cluster=True,\n",
        "    xticklabels=True,\n",
        "    yticklabels=True\n",
        ")\n",
        "plt.suptitle(f\"Hierarchical Clustering (Linkage: Average, Metric: Cosine)\", y=1.02, fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gghjIDmyk6l"
      },
      "outputs": [],
      "source": [
        "# --- Prepare and Save a Final CSV Report ---\n",
        "\n",
        "report_rows = []\n",
        "for index, row in taxonomy_df.iterrows():\n",
        "    for gesture in row['gestures']:\n",
        "        report_rows.append({\n",
        "            'Cluster_ID': row['cluster_id'],\n",
        "            'Taxonomic_Label': row['llm_label'],\n",
        "            'Taxonomic_Definition': row['llm_definition'],\n",
        "            'Representative_Gesture_Name': gesture,\n",
        "            'Original_Synonyms_Merged': ', '.join(row['synonyms_included'])\n",
        "        })\n",
        "\n",
        "final_report_df = pd.DataFrame(report_rows)\n",
        "\n",
        "# Save the final structured report\n",
        "final_report_df.to_csv('final_gesture_taxonomy_report.csv', index=False)\n",
        "print(\"Final taxonomy report saved to 'final_gesture_taxonomy_report.csv'\")\n",
        "print(\"\\nFirst 5 rows of the report:\")\n",
        "print(final_report_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu_9kUi6ymEW"
      },
      "outputs": [],
      "source": [
        "# Convert CSV to XLSX\n",
        "# Add a new cell to convert the CSV file to XLSX\n",
        "csv_file_path = \"CSV_FILE_PATH_HERE\"  # Path to the CSV file generated above\n",
        "xlsx_file_path = \"XLSX_FILE_PATH_HERE\"  # Path where the XLSX file will be saved\n",
        "\n",
        "try:\n",
        "    # Read the CSV file into a pandas dataframe\n",
        "    df_csv = pd.read_csv(csv_file_path)\n",
        "\n",
        "    # Write the dataframe to an XLSX file\n",
        "    df_csv.to_excel(xlsx_file_path, index=False)\n",
        "\n",
        "    print(f\"Successfully converted '{csv_file_path}' to '{xlsx_file_path}'\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xusF_614ynIW"
      },
      "outputs": [],
      "source": [
        "# --- Generate Dendrogram ---\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'df_dist' in locals():\n",
        "    print(\"Generating dendrogram...\")\n",
        "\n",
        "    # Use the linkage function from scipy.cluster.hierarchy\n",
        "    # Use the 'average' method and 'cosine' metric to match the clustering\n",
        "    linked = linkage(df_dist, method='average', metric='cosine')\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    dendrogram(linked,\n",
        "               orientation='top',\n",
        "               labels=df_dist.index.tolist(),\n",
        "               distance_sort='descending',\n",
        "               show_leaf_counts=True)\n",
        "    plt.title('Dendrogram of Gesture Clustering (Average Linkage, Cosine Distance)')\n",
        "    plt.ylabel('Cosine Distance')\n",
        "    plt.xlabel('Gestures')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Skipping dendrogram generation as distance matrix 'df_dist' is missing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp0VCHW151sA"
      },
      "outputs": [],
      "source": [
        "# Plot Color-Coded Dendrogram #\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    with open(\"final_taxonomy.json\", \"r\") as f:\n",
        "        final_taxonomy = json.load(f)\n",
        "    print(\"Loaded final_taxonomy from JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load final_taxonomy: {e}\")\n",
        "    final_taxonomy = None\n",
        "\n",
        "# Make sure all required objects are present\n",
        "if 'df_dist' in locals() and 'final_taxonomy' in locals():\n",
        "    print(\"Generating dendrogram with LLM labels and colors...\")\n",
        "\n",
        "    # Step 1: Build mapping dictionaries\n",
        "    gesture_to_cluster_id = {}\n",
        "    gesture_to_llm_label = {}\n",
        "\n",
        "    for cluster in final_taxonomy:\n",
        "        cluster_id = cluster['cluster_id']\n",
        "        llm_label = cluster['llm_label']\n",
        "        for gesture in cluster['gestures']:\n",
        "            gesture_to_cluster_id[gesture] = cluster_id\n",
        "            gesture_to_llm_label[gesture] = llm_label\n",
        "\n",
        "    # Step 2: Create labels and cluster IDs for each gesture in df_dist\n",
        "    labels = []\n",
        "    cluster_ids = []\n",
        "\n",
        "    missing_gestures = []\n",
        "\n",
        "    for gesture in df_dist.index.tolist():\n",
        "        cluster_id = gesture_to_cluster_id.get(gesture, -1)\n",
        "        llm_label = gesture_to_llm_label.get(gesture, \"Unknown\")\n",
        "        labels.append(f\"{gesture} ({llm_label})\")\n",
        "        cluster_ids.append(cluster_id)\n",
        "        if cluster_id == -1:\n",
        "            missing_gestures.append(gesture)\n",
        "\n",
        "    if missing_gestures:\n",
        "        print(f\"Warning: {len(missing_gestures)} gestures not found in taxonomy.\")\n",
        "        print(\"Example missing gesture(s):\", missing_gestures[:5])\n",
        "\n",
        "    # Step 3: Map cluster_id to colors\n",
        "    unique_clusters = sorted(set(cluster_ids))\n",
        "    cmap = cm.get_cmap('tab20', len(unique_clusters))\n",
        "    cluster_color_map = {cid: cmap(i) for i, cid in enumerate(unique_clusters)}\n",
        "    label_colors = [cluster_color_map[cid] for cid in cluster_ids]\n",
        "\n",
        "    # Step 4: Generate dendrogram\n",
        "    linked = linkage(df_dist, method='average', metric='cosine')\n",
        "\n",
        "    plt.figure(figsize=(22, 10))\n",
        "    dendro = dendrogram(linked,\n",
        "                        orientation='top',\n",
        "                        labels=labels,\n",
        "                        leaf_font_size=10,\n",
        "                        leaf_rotation=90,\n",
        "                        distance_sort='descending',\n",
        "                        show_leaf_counts=False)\n",
        "\n",
        "    # Step 5: Color the leaf labels manually\n",
        "    ax = plt.gca()\n",
        "    xlbls = ax.get_xmajorticklabels()\n",
        "\n",
        "    for lbl, color in zip(xlbls, [label_colors[i] for i in dendro['leaves']]):\n",
        "        lbl.set_color(color)\n",
        "\n",
        "    plt.title('Dendrogram of Gestures with LLM Cluster Labels')\n",
        "    plt.ylabel('Cosine Distance')\n",
        "    plt.xlabel('Gesture Names (Colored by Cluster)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Missing required data for dendrogram generation (df_dist or final_taxonomy).\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
